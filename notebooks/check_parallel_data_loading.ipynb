{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dchro\\AppData\\Local\\Temp\\ipykernel_5548\\489857577.py:150: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"../config/\", config_name=\"main.yaml\")\n",
      "usage: ipykernel_launcher.py [--help] [--hydra-help] [--version]\n",
      "                             [--cfg {job,hydra,all}] [--resolve]\n",
      "                             [--package PACKAGE] [--run] [--multirun]\n",
      "                             [--shell-completion] [--config-path CONFIG_PATH]\n",
      "                             [--config-name CONFIG_NAME]\n",
      "                             [--config-dir CONFIG_DIR]\n",
      "                             [--experimental-rerun EXPERIMENTAL_RERUN]\n",
      "                             [--info [{all,config,defaults,defaults-tree,plugins,searchpath}]]\n",
      "                             [overrides ...]\n",
      "ipykernel_launcher.py: error: argument --shell-completion/-sc: ignored explicit argument '9034'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\argparse.py:1866\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1866\u001b[0m     namespace, args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_known_args(args, namespace)\n\u001b[0;32m   1867\u001b[0m \u001b[39mexcept\u001b[39;00m ArgumentError:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\argparse.py:2079\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2078\u001b[0m     \u001b[39m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[1;32m-> 2079\u001b[0m     start_index \u001b[39m=\u001b[39m consume_optional(start_index)\n\u001b[0;32m   2081\u001b[0m \u001b[39m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\argparse.py:2001\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   2000\u001b[0m         msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39mignored explicit argument \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 2001\u001b[0m         \u001b[39mraise\u001b[39;00m ArgumentError(action, msg \u001b[39m%\u001b[39m explicit_arg)\n\u001b[0;32m   2003\u001b[0m \u001b[39m# if there is no explicit argument, try to match the\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[39m# optional's string arguments with the following strings\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[39m# if successful, exit the loop\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument --shell-completion/-sc: ignored explicit argument '9034'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dchro\\Documents\\MLOps\\mlops_project\\notebooks\\check_parallel_data_loading.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/dchro/Documents/MLOps/mlops_project/notebooks/check_parallel_data_loading.ipynb#W0sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTime taken: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(end\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/dchro/Documents/MLOps/mlops_project/notebooks/check_parallel_data_loading.ipynb#W0sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m main()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hydra\\main.py:86\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[1;34m(cfg_passthrough)\u001b[0m\n\u001b[0;32m     85\u001b[0m args_parser \u001b[39m=\u001b[39m get_args_parser()\n\u001b[1;32m---> 86\u001b[0m args \u001b[39m=\u001b[39m args_parser\u001b[39m.\u001b[39;49mparse_args()\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mexperimental_rerun \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\argparse.py:1833\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1832\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_args\u001b[39m(\u001b[39mself\u001b[39m, args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, namespace\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1833\u001b[0m     args, argv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_known_args(args, namespace)\n\u001b[0;32m   1834\u001b[0m     \u001b[39mif\u001b[39;00m argv:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\argparse.py:1869\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1868\u001b[0m         err \u001b[39m=\u001b[39m _sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1869\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(\u001b[39mstr\u001b[39;49m(err))\n\u001b[0;32m   1870\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\argparse.py:2594\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2593\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[1;32m-> 2594\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\argparse.py:2581\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2580\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m-> 2581\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2097\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2095\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2096\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2097\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2098\u001b[0m                                                      value))\n\u001b[0;32m   2099\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2101\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    569\u001b[0m             etype,\n\u001b[0;32m    570\u001b[0m             evalue,\n\u001b[0;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[0;32m    573\u001b[0m             context,\n\u001b[0;32m    574\u001b[0m         )\n\u001b[0;32m    575\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1436\u001b[0m     \u001b[39mself\u001b[39;49m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1437\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1327\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1328\u001b[0m     )\n\u001b[0;32m   1329\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m   1174\u001b[0m                                                            tb_offset)\n\u001b[0;32m   1176\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(\u001b[39mstr\u001b[39m(etype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\mlops2\\lib\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(cf\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[0;32m   1132\u001b[0m         \u001b[39mif\u001b[39;00m mod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# import hydra\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dotenv import load_dotenv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data.make_dataset import make_dataset\n",
    "\n",
    "# current_script_directory = os.path.dirname(os.path.abspath(\"C:\\Users\\dchro\\Documents\\MLOps\\mlops_project\\notebooks\\check_parallel_data_loading.ipynb\"))\n",
    "# parent_directory = os.path.abspath(os.path.join(current_script_directory, \"..\"))\n",
    "# root_directory = os.path.abspath(os.path.join(current_script_directory, \"..\"))\n",
    "save_path = os.path.join(\"C:/Users/dchro/Documents/MLOps/mlops_project\", \"models\", \"mobilenetv3_fine_tuned.pth\")\n",
    "\n",
    "config = \"\"\"train_transforms:\n",
    "  resize:\n",
    "    _target_: torchvision.transforms.Resize\n",
    "    size: [256, 256]\n",
    "  random_crop:\n",
    "    _target_: torchvision.transforms.RandomResizedCrop\n",
    "    size: [224, 224]\n",
    "  random_hor_flip:\n",
    "    _target_: torchvision.transforms.RandomHorizontalFlip\n",
    "  random_rot:\n",
    "    _target_: torchvision.transforms.RandomRotation\n",
    "    degrees: 30\n",
    "  random_affine:\n",
    "    _target_: torchvision.transforms.RandomAffine\n",
    "    degrees: 0\n",
    "    translate: [0.1, 0.1]\n",
    "  random_persp:\n",
    "    _target_: torchvision.transforms.RandomPerspective\n",
    "    distortion_scale: 0.5\n",
    "    p: 0.5\n",
    "  to_tensor:\n",
    "    _target_: torchvision.transforms.ToTensor\n",
    "  norma:\n",
    "    _target_: torchvision.transforms.Normalize\n",
    "    mean: [0.485, 0.456, 0.406]\n",
    "    std: [0.229, 0.224, 0.225]\"\"\"\n",
    "\n",
    "# @hydra.main(config_path=\"../../config/\", config_name=\"main.yaml\")\n",
    "\n",
    "def train_model(num_workers = 0):\n",
    "    # Data Load\n",
    "    print(\"Loading data...\")\n",
    "    num_classes = 38\n",
    "    trainset = make_dataset(config, dataset_type=\"train\")\n",
    "    val_set = make_dataset(config, dataset_type=\"val\")\n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=32, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    print(\"Defining model...\")\n",
    "    # Model definition\n",
    "    model = timm.create_model(\n",
    "        \"mobilenetv3_large_100\", pretrained=True, num_classes=num_classes\n",
    "    )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 2  # Number of epochs to wait for improvement\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    print(\"Training start...\")\n",
    "    # Training loop\n",
    "    for ep in range(10):\n",
    "        total_loss = 0\n",
    "        num_correct = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(inputs)\n",
    "            batch_loss = criterion(y_hat, labels)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += float(batch_loss)\n",
    "            num_correct += int(torch.sum(torch.argmax(y_hat, dim=1) == labels))\n",
    "\n",
    "            print(\n",
    "                \"EPOCH: {:5}    BATCH: {:5}/{:5}    LOSS: {:.3f}\".format(\n",
    "                    ep, batch_idx, len(train_loader), batch_loss\n",
    "                )\n",
    "            )\n",
    "\n",
    "        epoch_loss = total_loss / len(trainset)\n",
    "        epoch_accuracy = num_correct / len(trainset)\n",
    "\n",
    "        print(\n",
    "            \"EPOCH: {:5}    LOSS: {:.3f}    ACCURACY: {:.3f}\".format(\n",
    "                ep, epoch_loss, epoch_accuracy\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        num_val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (val_inputs, val_labels) in enumerate(val_loader):\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "                total_val_loss += float(val_loss)\n",
    "                num_val_correct += int(\n",
    "                    torch.sum(torch.argmax(val_outputs, dim=1) == val_labels)\n",
    "                )\n",
    "\n",
    "        val_epoch_loss = total_val_loss / len(val_set)\n",
    "        val_epoch_accuracy = num_val_correct / len(val_set)\n",
    "        print(\n",
    "            \"EPOCH: {:5}    VAL LOSS: {:.3f}    VAL ACCURACY: {:.3f}\".format(\n",
    "                ep, val_epoch_loss, val_epoch_accuracy\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            epochs_without_improvement = 0\n",
    "\n",
    "            # save the best model checkpoint here\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # Check if we should stop training\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping after {ep + 1} epochs\")\n",
    "            break\n",
    "\n",
    "    # Save the trained model\n",
    "\n",
    "    print(\"Best Model saved!\")\n",
    "    print(\"Save path: \", save_path)\n",
    "\n",
    "\n",
    "# Run training, save model and print metrics\n",
    "@hydra.main(config_path=\"../config/\", config_name=\"main.yaml\")\n",
    "def main(cfg):\n",
    "\n",
    "    import time\n",
    "    for i in [1, 2, 4]:\n",
    "        # Print time for each run\n",
    "        print(f\"Running with {i} workers\")\n",
    "        start = time.time()\n",
    "        train_model(cfg, i)\n",
    "        end = time.time()\n",
    "        print(f\"Time taken: {round(end - start, 2)}\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
