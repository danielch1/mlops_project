{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lego_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths, path, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list): List of file paths for the images.\n",
    "            labels (list): List of corresponding labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = Image.open(os.path.join(self.path,img_path)).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lennart\\Documents\\GitHub\\mlops_project\n",
      "c:\\Users\\Lennart\\Documents\\GitHub\\mlops_project\\data\\external\\lego_dataset\\index.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marvel/0001/001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marvel/0001/002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marvel/0001/003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marvel/0001/004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marvel/0001/005.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>star-wars/0017/006.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>star-wars/0017/007.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>star-wars/0017/008.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>star-wars/0017/009.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>star-wars/0017/010.jpg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path  class_id\n",
       "0       marvel/0001/001.jpg         1\n",
       "1       marvel/0001/002.jpg         1\n",
       "2       marvel/0001/003.jpg         1\n",
       "3       marvel/0001/004.jpg         1\n",
       "4       marvel/0001/005.jpg         1\n",
       "..                      ...       ...\n",
       "366  star-wars/0017/006.jpg        38\n",
       "367  star-wars/0017/007.jpg        38\n",
       "368  star-wars/0017/008.jpg        38\n",
       "369  star-wars/0017/009.jpg        38\n",
       "370  star-wars/0017/010.jpg        38\n",
       "\n",
       "[371 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of filenames\n",
    "parent = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(parent)\n",
    "path_index = Path('data/external/lego_dataset/index.csv')\n",
    "print(os.path.join(parent,path_index))\n",
    "#path = \"C:/Users/Lennart/Documents/GitHub/mlops_project/data/external/lego_dataset\"\n",
    "index = pd.read_csv(os.path.join(parent,path_index))\n",
    "\n",
    "index\n",
    "#labels = index[\"class_id\"]-1\n",
    "#files = index[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "366    37\n",
       "367    37\n",
       "368    37\n",
       "369    37\n",
       "370    37\n",
       "Name: class_id, Length: 371, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Lego_Dataset(file_paths=files, path = path, labels=labels,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:     0/tBATCH:     0/   12/tLOSS: 3.745\n",
      "EPOCH:     0/tBATCH:     1/   12/tLOSS: 7.821\n",
      "EPOCH:     0/tBATCH:     2/   12/tLOSS: 4.039\n",
      "EPOCH:     0/tBATCH:     3/   12/tLOSS: 4.437\n",
      "EPOCH:     0/tBATCH:     4/   12/tLOSS: 3.551\n",
      "EPOCH:     0/tBATCH:     5/   12/tLOSS: 3.106\n",
      "EPOCH:     0/tBATCH:     6/   12/tLOSS: 3.540\n",
      "EPOCH:     0/tBATCH:     7/   12/tLOSS: 2.220\n",
      "EPOCH:     0/tBATCH:     8/   12/tLOSS: 3.269\n",
      "EPOCH:     0/tBATCH:     9/   12/tLOSS: 3.076\n",
      "EPOCH:     0/tBATCH:    10/   12/tLOSS: 2.372\n",
      "EPOCH:     0/tBATCH:    11/   12/tLOSS: 2.769\n",
      "EPOCH:     0/tLOSS: 0.118/tACCURACY: 0.194\n",
      "EPOCH:     1/tBATCH:     0/   12/tLOSS: 1.772\n",
      "EPOCH:     1/tBATCH:     1/   12/tLOSS: 1.713\n",
      "EPOCH:     1/tBATCH:     2/   12/tLOSS: 1.189\n",
      "EPOCH:     1/tBATCH:     3/   12/tLOSS: 1.006\n",
      "EPOCH:     1/tBATCH:     4/   12/tLOSS: 0.682\n",
      "EPOCH:     1/tBATCH:     5/   12/tLOSS: 1.203\n",
      "EPOCH:     1/tBATCH:     6/   12/tLOSS: 0.670\n",
      "EPOCH:     1/tBATCH:     7/   12/tLOSS: 0.644\n",
      "EPOCH:     1/tBATCH:     8/   12/tLOSS: 1.073\n",
      "EPOCH:     1/tBATCH:     9/   12/tLOSS: 0.955\n",
      "EPOCH:     1/tBATCH:    10/   12/tLOSS: 0.833\n",
      "EPOCH:     1/tBATCH:    11/   12/tLOSS: 0.655\n",
      "EPOCH:     1/tLOSS: 0.033/tACCURACY: 0.687\n",
      "EPOCH:     2/tBATCH:     0/   12/tLOSS: 0.407\n",
      "EPOCH:     2/tBATCH:     1/   12/tLOSS: 0.382\n",
      "EPOCH:     2/tBATCH:     2/   12/tLOSS: 1.275\n",
      "EPOCH:     2/tBATCH:     3/   12/tLOSS: 0.820\n",
      "EPOCH:     2/tBATCH:     4/   12/tLOSS: 0.377\n",
      "EPOCH:     2/tBATCH:     5/   12/tLOSS: 0.265\n",
      "EPOCH:     2/tBATCH:     6/   12/tLOSS: 0.418\n",
      "EPOCH:     2/tBATCH:     7/   12/tLOSS: 0.336\n",
      "EPOCH:     2/tBATCH:     8/   12/tLOSS: 1.010\n",
      "EPOCH:     2/tBATCH:     9/   12/tLOSS: 0.604\n",
      "EPOCH:     2/tBATCH:    10/   12/tLOSS: 0.294\n",
      "EPOCH:     2/tBATCH:    11/   12/tLOSS: 0.108\n",
      "EPOCH:     2/tLOSS: 0.017/tACCURACY: 0.857\n",
      "EPOCH:     3/tBATCH:     0/   12/tLOSS: 0.603\n",
      "EPOCH:     3/tBATCH:     1/   12/tLOSS: 0.768\n",
      "EPOCH:     3/tBATCH:     2/   12/tLOSS: 0.612\n",
      "EPOCH:     3/tBATCH:     3/   12/tLOSS: 0.130\n",
      "EPOCH:     3/tBATCH:     4/   12/tLOSS: 0.704\n",
      "EPOCH:     3/tBATCH:     5/   12/tLOSS: 0.160\n",
      "EPOCH:     3/tBATCH:     6/   12/tLOSS: 0.204\n",
      "EPOCH:     3/tBATCH:     7/   12/tLOSS: 0.253\n",
      "EPOCH:     3/tBATCH:     8/   12/tLOSS: 0.758\n",
      "EPOCH:     3/tBATCH:     9/   12/tLOSS: 0.687\n",
      "EPOCH:     3/tBATCH:    10/   12/tLOSS: 0.475\n",
      "EPOCH:     3/tBATCH:    11/   12/tLOSS: 0.613\n",
      "EPOCH:     3/tLOSS: 0.016/tACCURACY: 0.868\n",
      "EPOCH:     4/tBATCH:     0/   12/tLOSS: 0.031\n",
      "EPOCH:     4/tBATCH:     1/   12/tLOSS: 0.186\n",
      "EPOCH:     4/tBATCH:     2/   12/tLOSS: 0.142\n",
      "EPOCH:     4/tBATCH:     3/   12/tLOSS: 0.340\n",
      "EPOCH:     4/tBATCH:     4/   12/tLOSS: 0.279\n",
      "EPOCH:     4/tBATCH:     5/   12/tLOSS: 0.437\n",
      "EPOCH:     4/tBATCH:     6/   12/tLOSS: 0.356\n",
      "EPOCH:     4/tBATCH:     7/   12/tLOSS: 0.339\n",
      "EPOCH:     4/tBATCH:     8/   12/tLOSS: 0.362\n",
      "EPOCH:     4/tBATCH:     9/   12/tLOSS: 0.274\n",
      "EPOCH:     4/tBATCH:    10/   12/tLOSS: 0.255\n",
      "EPOCH:     4/tBATCH:    11/   12/tLOSS: 0.163\n",
      "EPOCH:     4/tLOSS: 0.009/tACCURACY: 0.914\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "num_epochs = 5\n",
    "lr = 0.003\n",
    "\n",
    "num_classes = 38 \n",
    "\n",
    "\n",
    "#model = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "model = timm.create_model('mobilenetv3_large_100', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Adjust this according to your needs\n",
    "\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    \n",
    "\n",
    "    total_loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(inputs)\n",
    "        batch_loss = criterion(y_hat, labels)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(batch_loss)\n",
    "        num_correct += int(torch.sum(torch.argmax(y_hat, dim=1) == labels))\n",
    "\n",
    "        \n",
    "        print(\n",
    "            \"EPOCH: {:5}/tBATCH: {:5}/{:5}/tLOSS: {:.3f}\".format(\n",
    "                ep, batch_idx, len(train_loader), batch_loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "    epoch_loss = total_loss / len(trainset)\n",
    "    epoch_accuracy = num_correct / len(trainset)\n",
    "    print(\n",
    "        \"EPOCH: {:5}/tLOSS: {:.3f}/tACCURACY: {:.3f}\".format(\n",
    "            ep, epoch_loss, epoch_accuracy\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Validation loop (optional)\n",
    "    #model.eval()\n",
    "    #with torch.no_grad():\n",
    "    #    for inputs, labels in val_loader:\n",
    "    #        outputs = model(inputs)\n",
    "            # Calculate validation loss and metrics\n",
    "\n",
    "# Save the trained model\n",
    "#torch.save(model.state_dict(), 'mobilenetv3_fine_tuned.pth')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_positive_thinkers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
