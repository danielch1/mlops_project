{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lego_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths, path, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list): List of file paths for the images.\n",
    "            labels (list): List of corresponding labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = Image.open(os.path.join(self.path,img_path)).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of filenames\n",
    "path = \"/Users/LeMarx/Documents/01_Projects/mlops_project/data/external/lego_dataset\"\n",
    "index = pd.read_csv(\"/Users/LeMarx/Documents/01_Projects/mlops_project/data/external/lego_dataset/index.csv\")\n",
    "labels = index[\"class_id\"]-1\n",
    "files = index[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "366    37\n",
       "367    37\n",
       "368    37\n",
       "369    37\n",
       "370    37\n",
       "Name: class_id, Length: 371, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Lego_Dataset(file_paths=files, path = path, labels=labels,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:     0\tBATCH:     0/   12\tLOSS: 3.649\n",
      "EPOCH:     0\tBATCH:     1/   12\tLOSS: 74.196\n",
      "EPOCH:     0\tBATCH:     2/   12\tLOSS: 41.695\n",
      "EPOCH:     0\tBATCH:     3/   12\tLOSS: 11.657\n",
      "EPOCH:     0\tBATCH:     4/   12\tLOSS: 3.670\n",
      "EPOCH:     0\tBATCH:     5/   12\tLOSS: 3.639\n",
      "EPOCH:     0\tBATCH:     6/   12\tLOSS: 3.637\n",
      "EPOCH:     0\tBATCH:     7/   12\tLOSS: 3.639\n",
      "EPOCH:     0\tBATCH:     8/   12\tLOSS: 3.639\n",
      "EPOCH:     0\tBATCH:     9/   12\tLOSS: 3.637\n",
      "EPOCH:     0\tBATCH:    10/   12\tLOSS: 3.636\n",
      "EPOCH:     0\tBATCH:    11/   12\tLOSS: 3.637\n",
      "EPOCH:     0\tLOSS: 0.432\tACCURACY: 0.022\n",
      "EPOCH:     1\tBATCH:     0/   12\tLOSS: 3.637\n",
      "EPOCH:     1\tBATCH:     1/   12\tLOSS: 3.637\n",
      "EPOCH:     1\tBATCH:     2/   12\tLOSS: 3.638\n",
      "EPOCH:     1\tBATCH:     3/   12\tLOSS: 3.636\n",
      "EPOCH:     1\tBATCH:     4/   12\tLOSS: 3.640\n",
      "EPOCH:     1\tBATCH:     5/   12\tLOSS: 3.635\n",
      "EPOCH:     1\tBATCH:     6/   12\tLOSS: 3.637\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/LeMarx/Documents/01_Projects/mlops_project/notebooks/trial_run_make_dataset.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/LeMarx/Documents/01_Projects/mlops_project/notebooks/trial_run_make_dataset.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/LeMarx/Documents/01_Projects/mlops_project/notebooks/trial_run_make_dataset.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/LeMarx/Documents/01_Projects/mlops_project/notebooks/trial_run_make_dataset.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m y_hat \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/LeMarx/Documents/01_Projects/mlops_project/notebooks/trial_run_make_dataset.ipynb#X11sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m batch_loss \u001b[39m=\u001b[39m criterion(y_hat, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/LeMarx/Documents/01_Projects/mlops_project/notebooks/trial_run_make_dataset.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m batch_loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/the_positive_thinkers/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/the_positive_thinkers/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/the_positive_thinkers/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/the_positive_thinkers/lib/python3.9/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    167\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[1;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/the_positive_thinkers/lib/python3.9/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/the_positive_thinkers/lib/python3.9/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "num_epochs = 5\n",
    "lr = 0.003\n",
    "\n",
    "num_classes = 38 \n",
    "\n",
    "\n",
    "#model = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels= 3, out_channels=32,kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=254016,out_features=num_classes)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Adjust this according to your needs\n",
    "\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    \n",
    "\n",
    "    total_loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(inputs)\n",
    "        batch_loss = criterion(y_hat, labels)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(batch_loss)\n",
    "        num_correct += int(torch.sum(torch.argmax(y_hat, dim=1) == labels))\n",
    "\n",
    "        \n",
    "        print(\n",
    "            \"EPOCH: {:5}\\tBATCH: {:5}/{:5}\\tLOSS: {:.3f}\".format(\n",
    "                ep, batch_idx, len(train_loader), batch_loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "    epoch_loss = total_loss / len(trainset)\n",
    "    epoch_accuracy = num_correct / len(trainset)\n",
    "    print(\n",
    "        \"EPOCH: {:5}\\tLOSS: {:.3f}\\tACCURACY: {:.3f}\".format(\n",
    "            ep, epoch_loss, epoch_accuracy\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Validation loop (optional)\n",
    "    #model.eval()\n",
    "    #with torch.no_grad():\n",
    "    #    for inputs, labels in val_loader:\n",
    "    #        outputs = model(inputs)\n",
    "            # Calculate validation loss and metrics\n",
    "\n",
    "# Save the trained model\n",
    "#torch.save(model.state_dict(), 'mobilenetv3_fine_tuned.pth')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_positive_thinkers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
